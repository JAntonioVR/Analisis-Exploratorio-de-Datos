}
datos$ZTLIBROP<-not_available(datos$ZTLIBROP)
#Definimos las medidas resistentes
PMC<-function(x){ return((as.double(quantile(x,0.25))+as.double(quantile(x,0.75)))/2)}
trimedia<-function(x){return((median(x)+PMC(x))/2)}
centrimedia<-function(x){
indices<-(x>quantile(x,0.25)&x<quantile(x,0.75))
valores<-x[indices]
return(sum(valores)/length(valores))
}
RIQ<-function(x){return(quantile(x,0.75)-quantile(x,0.25))}
MEDA<-function(x){return(median(abs(x-median(x))))}
CVc<-function(x){return((quantile(x,0.75)-quantile(x,0.25))/(quantile(x,0.75)+quantile(x,0.25)))}
H1<-function(x){return((quantile(x,0.25)+quantile(x,0.75)-2*median(x))/(2*median(x)))}
H2<-function(x){return(median(x)-(quantile(x,0.1)+quantile(x,0.9))/(2))}
H3<-function(x){return(H2(x)/median(x))}
#Creamos una función que aplique todas estas medidas
descriptivo<-function(x){
temp<-rbind(PMC(x),trimedia(x),centrimedia(x))
rownames(temp)<-c("PMC","Trimedia","Centrimedia")
centralidad<-list(clasica=list(media=mean(x)),resistente=temp)
temp<-rbind(RIQ(x),MEDA(x),CVc(x))
rownames(temp)<-c("Rango Inter-Cuartílico","MEDA","CVc")
dispersion<-list(clasica=list(desviación_típica=sd(x),Coef_varización=sd(x)/mean(x),rango=range(x)),resistente=temp)
temp<-rbind(H1(x),H2(x),H3(x))
rownames(temp)<-c("Asimetría de Yule","Asimetría de Kelly","Asimetría de Kelly adimensional")
forma<-list(clasica=list(skewness=skewness(x),kurtosis=kurtosis(x)),resistente=temp)
cat(names(x))
return(list(centralidad=centralidad,dispersion=dispersion,forma=forma))
}
descriptivo(datos[,2])
hist(col="darkblue",datos[,2],main="Densidad de población")
descriptivo(datos[,3])
hist(col="darkblue",datos[,3],main="Mortalidad infantil")
descriptivo(datos[,4])
hist(col="darkblue",datos[,4],main="Esperanza de vida")
descriptivo(datos[,5])
hist(col="darkblue",datos[,5],main="Porcentaje de población urbana")
descriptivo(datos[,6])
hist(col="darkblue",datos[,6],main="Tasa de médicos por habitante")
descriptivo(datos[,7])
hist(col="darkblue",datos[,7],main="Población del sector agrícola")
descriptivo(datos[,8])
hist(col="darkblue",datos[,8],main="Población del sector servicios")
descriptivo(datos[,9])
hist(col="darkblue",datos[,9],main="Número de libros publicados")
descriptivo(datos[,10])
hist(col="darkblue",datos[,10],main="Cociente entre el número de individuos en ejército de tierra y población total del estado")
descriptivo(datos[,11])
hist(col="darkblue",datos[,11],main="Cociente entre población activa y total")
descriptivo(datos[,12])
hist(col="darkblue",datos[,12],main="Tasa de consumo energético")
summary(datos[,-1])
par(mar=c(1,1,1,1))
par(mfrow=c(3,4))
invisible(apply(datos[,-1], 2,function(x){hist(x,main=NULL,col="darkblue",xlab=NULL,ylab=NULL)}))
colfunc<-colorRampPalette(c("darkblue","yellow"))
boxplot(datos[,-1],
xlab=NULL,
ylab=NULL,
col=colfunc(11),
las=2)
outlier<-function(data,na.rm=T){
H<-1.5*IQR(data)
if(any(data<=(quantile(data,0.25,na.rm = T)-H))){
data[data<=quantile(data,0.25,na.rm = T)-H]<-NA
data[is.na(data)]<-mean(data,na.rm=T)
data<-outlier(data)}
if(any(data>=(quantile(data,0.75, na.rm = T)+H))){
data[data>=quantile(data,0.75, na.rm = T)+H]<-NA
data[is.na(data)]<-mean(data,na.rm=T)
data<-outlier(data)
}
return(data)
}
datos[,-1:-2]<-apply(datos[,-1:-2], 2, outlier)
boxplot(datos[,-1],
xlab=NULL,
ylab=NULL,
col=colfunc(11),
las=2)
par(mar=c(1,1,1,1))
par(mfrow=c(3,4))
invisible(apply(datos[,-1], 2, function(x){
qqnorm(x,main=NULL)
abline(a=0,b=1,col="red")
}))
datos_aux <- datos[,-1]
datos_enteros$continente <- c(
"africa", "africa", "america", "oceania",
"america", "america", "america", "asia",
"asia", "africa", "europa", "asia",
"europa", "europa", "asia", "asia",
"asia", "asia", "europa", "asia", "asia",
"africa", "america", "africa", "asia", "europa",
"europa", "europa", "europa", "europa",
"europa", "asia", "america", "asia")
ind<-which(datos_enteros$continente=="europa"|datos_enteros$continente=="asia"|datos_enteros$continente=="africa")
factores<-datos_enteros$continente[ind]
#Como se han eliminado los valores outlier, usamos con centro la media en vez de la mediana
#H0:homocedasticidad
apply(datos_aux[ind,], 2, function(x){
if(leveneTest(x,as.factor(factores),center=median)$"Pr(>F)"[1]>0.05){
"Existe homocedasticidad entre los grupos"
}
else{"No existe homocedasticidad entre los grupos"}
})
summary(datos_enteros[,c(-1,-13)])
summary(datos[,-1])
datos_pca = datos[,-1] # Eliminamos la primera columna, que es categórica
cor(datos_pca)
poly_cor<-hetcor(datos_pca)$correlations
ggcorrplot(poly_cor, type="lower",hc.order=T)
cor(datos_pca$ZESPVIDA,datos_pca$ZTMINFAN)
cor(datos_pca$ZPAGRICU,datos_pca$ZPOBURB)
cor(datos_pca$ZPSERVI, datos_pca$ZPAGRICU)
cortest.bartlett(cor(datos_pca), n=100)
# scale y center están a True porque consideramos los datos normalizados
PCA<-prcomp(datos_pca, scale=T, center = T)
PCA$rotation
summary(PCA)
varianza_explicada <- PCA$sdev^2 / sum(PCA$sdev^2)
ggplot(data = data.frame(varianza_explicada, pc = 1:11),
aes(x = pc, y = varianza_explicada, fill=varianza_explicada )) +
geom_col(width = 0.3) +
scale_y_continuous(limits = c(0,0.6)) + theme_bw() +
labs(x = "Componente principal", y= " Proporción de varianza explicada")
varianza_acum<-cumsum(varianza_explicada)
ggplot( data = data.frame(varianza_acum, pc = 1:11),
aes(x = pc, y = varianza_acum ,fill=varianza_acum )) +
geom_col(width = 0.5) +
scale_y_continuous(limits = c(0,1)) +
theme_bw() +
labs(x = "Componente principal",
y = "Proporci?n varianza acumulada")
PCA$sdev^2
mean(PCA$sdev^2)
# Entre la PC1 y la PC2
fviz_pca_var(PCA, axes=c(1,2),
repel=TRUE,col.var="cos2",
legend.title="Distancia")+theme_bw()
# Entre la PC1 y la PC3
fviz_pca_var(PCA,axes=c(1,3),
repel=TRUE,col.var="cos2",
legend.title="Distancia")+theme_bw()
#Entre la PC2 y la PC3
fviz_pca_var(PCA,axes=c(2,3),
repel=TRUE,col.var="cos2",
legend.title="Distancia")+theme_bw()
datos_fa = datos_pca
corrplot(cor(datos_fa), order = "hclust", tl.col='black', tl.cex=1,
col=colorRampPalette(c("blue","white","red"))(200))
scree(poly_cor)
fa.parallel(poly_cor,n.obs=200,fa="fa",fm="minres")
factanal(datos_fa,factors=2, rotation="none")
factanal(datos_fa,factors=3, rotation="none")
factanal(datos_fa,factors=2, rotation="none")
print("###############################################")
factanal(datos_fa,factors=3, rotation="none")
factanal(datos_fa,factors=2, rotation="none")
print("\n###############################################")
factanal(datos_fa,factors=3, rotation="none")
factanal(datos_fa,factors=2, rotation="none")
print("###############################################")
factanal(datos_fa,factors=3, rotation="none")
modelo_varimax<-fa(poly_cor,nfactors = 3,rotate = "none",
fa="mle")
modelo_varimax<-fa(poly_cor,nfactors = 2,rotate = "none",
fa="mle")
modelo_varimax<-fa(poly_cor,nfactors = 3,rotate = "none",
fa="mle")
modelo_varimax<-fa(poly_cor,nfactors = 4,rotate = "none",
fa="mle")
modelo_varimax<-fa(poly_cor,nfactors = 3,rotate = "none",
fa="mle")
print(modelo_varimax$loadings,cut=0)
fa.diagram(modelo_varimax)
datos_da = datos_fa
datos_tidy <- melt(datos_da, value.name = "valor")
aggregate(formula = valor ~ variable, data = datos_tidy,
FUN = function(x){shapiro.test(x)$p.value})
outliers <- mvn(data = datos_da, mvnTest = "hz", multivariateOutlierMethod = "quan")
royston_test <- mvn(data = datos_da, mvnTest = "royston", multivariatePlot = "qq")
royston_test$multivariateNormality
hz_test <- mvn(data = datos_da, mvnTest = "hz")
hz_test$multivariateNormality
outlier<-function(data,na.rm=T){
H<-1.5*IQR(data)
if(any(data<=(quantile(data,0.25,na.rm = T)-H))){
data[data<=quantile(data,0.25,na.rm = T)-H]<-NA
data[is.na(data)]<-mean(data,na.rm=T)
data<-outlier(data)}
if(any(data>=(quantile(data,0.75, na.rm = T)+H))){
data[data>=quantile(data,0.75, na.rm = T)+H]<-NA
data[is.na(data)]<-mean(data,na.rm=T)
data<-outlier(data)
}
return(data)
}
datos[,-1]<-apply(datos[,-1], 2, outlier)
# install.packages("EnvStats")
library(EnvStats)
library(car)
library(foreign)
library(psych)
library(ggplot2)
library(reshape2)
library(factoextra)
library(polycor)
library(ggcorrplot)
library(corrplot)
library(stats)
library(reshape2)
library(knitr)
library(dplyr)
library(MVN)
datos_enteros<-read.spss("DB_3.sav", to.data.frame = TRUE)
datos_enteros[11,"PAIS"] <- "espana" # Para evitar problemas de codificacion
datos = datos_enteros
head(datos)
cbind(apply(is.na(datos),2,sum),apply(is.na(datos),2,sum)/dim(datos)[1])
datos['marrueco','ZTLIBROP']
not_available<-function(data,na.rm=F){
data[is.na(data)]<-mean(data,na.rm=T)
data
}
datos$ZTLIBROP<-not_available(datos$ZTLIBROP)
#Definimos las medidas resistentes
PMC<-function(x){ return((as.double(quantile(x,0.25))+as.double(quantile(x,0.75)))/2)}
trimedia<-function(x){return((median(x)+PMC(x))/2)}
centrimedia<-function(x){
indices<-(x>quantile(x,0.25)&x<quantile(x,0.75))
valores<-x[indices]
return(sum(valores)/length(valores))
}
RIQ<-function(x){return(quantile(x,0.75)-quantile(x,0.25))}
MEDA<-function(x){return(median(abs(x-median(x))))}
CVc<-function(x){return((quantile(x,0.75)-quantile(x,0.25))/(quantile(x,0.75)+quantile(x,0.25)))}
H1<-function(x){return((quantile(x,0.25)+quantile(x,0.75)-2*median(x))/(2*median(x)))}
H2<-function(x){return(median(x)-(quantile(x,0.1)+quantile(x,0.9))/(2))}
H3<-function(x){return(H2(x)/median(x))}
#Creamos una función que aplique todas estas medidas
descriptivo<-function(x){
temp<-rbind(PMC(x),trimedia(x),centrimedia(x))
rownames(temp)<-c("PMC","Trimedia","Centrimedia")
centralidad<-list(clasica=list(media=mean(x)),resistente=temp)
temp<-rbind(RIQ(x),MEDA(x),CVc(x))
rownames(temp)<-c("Rango Inter-Cuartílico","MEDA","CVc")
dispersion<-list(clasica=list(desviación_típica=sd(x),Coef_varización=sd(x)/mean(x),rango=range(x)),resistente=temp)
temp<-rbind(H1(x),H2(x),H3(x))
rownames(temp)<-c("Asimetría de Yule","Asimetría de Kelly","Asimetría de Kelly adimensional")
forma<-list(clasica=list(skewness=skewness(x),kurtosis=kurtosis(x)),resistente=temp)
cat(names(x))
return(list(centralidad=centralidad,dispersion=dispersion,forma=forma))
}
descriptivo(datos[,2])
hist(col="darkblue",datos[,2],main="Densidad de población")
descriptivo(datos[,3])
hist(col="darkblue",datos[,3],main="Mortalidad infantil")
descriptivo(datos[,4])
hist(col="darkblue",datos[,4],main="Esperanza de vida")
descriptivo(datos[,5])
hist(col="darkblue",datos[,5],main="Porcentaje de población urbana")
descriptivo(datos[,6])
hist(col="darkblue",datos[,6],main="Tasa de médicos por habitante")
descriptivo(datos[,7])
hist(col="darkblue",datos[,7],main="Población del sector agrícola")
descriptivo(datos[,8])
hist(col="darkblue",datos[,8],main="Población del sector servicios")
descriptivo(datos[,9])
hist(col="darkblue",datos[,9],main="Número de libros publicados")
descriptivo(datos[,10])
hist(col="darkblue",datos[,10],main="Cociente entre el número de individuos en ejército de tierra y población total del estado")
descriptivo(datos[,11])
hist(col="darkblue",datos[,11],main="Cociente entre población activa y total")
descriptivo(datos[,12])
hist(col="darkblue",datos[,12],main="Tasa de consumo energético")
summary(datos[,-1])
par(mar=c(1,1,1,1))
par(mfrow=c(3,4))
invisible(apply(datos[,-1], 2,function(x){hist(x,main=NULL,col="darkblue",xlab=NULL,ylab=NULL)}))
colfunc<-colorRampPalette(c("darkblue","yellow"))
boxplot(datos[,-1],
xlab=NULL,
ylab=NULL,
col=colfunc(11),
las=2)
outlier<-function(data,na.rm=T){
H<-1.5*IQR(data)
if(any(data<=(quantile(data,0.25,na.rm = T)-H))){
data[data<=quantile(data,0.25,na.rm = T)-H]<-NA
data[is.na(data)]<-mean(data,na.rm=T)
data<-outlier(data)}
if(any(data>=(quantile(data,0.75, na.rm = T)+H))){
data[data>=quantile(data,0.75, na.rm = T)+H]<-NA
data[is.na(data)]<-mean(data,na.rm=T)
data<-outlier(data)
}
return(data)
}
datos[,-1]<-apply(datos[,-1], 2, outlier)
boxplot(datos[,-1],
xlab=NULL,
ylab=NULL,
col=colfunc(11),
las=2)
# install.packages("EnvStats")
library(EnvStats)
library(car)
library(foreign)
library(psych)
library(ggplot2)
library(reshape2)
library(factoextra)
library(polycor)
library(ggcorrplot)
library(corrplot)
library(stats)
library(reshape2)
library(knitr)
library(dplyr)
library(MVN)
datos_enteros<-read.spss("DB_3.sav", to.data.frame = TRUE)
datos_enteros[11,"PAIS"] <- "espana" # Para evitar problemas de codificacion
datos = datos_enteros
head(datos)
cbind(apply(is.na(datos),2,sum),apply(is.na(datos),2,sum)/dim(datos)[1])
datos['marrueco','ZTLIBROP']
not_available<-function(data,na.rm=F){
data[is.na(data)]<-mean(data,na.rm=T)
data
}
datos$ZTLIBROP<-not_available(datos$ZTLIBROP)
#Definimos las medidas resistentes
PMC<-function(x){ return((as.double(quantile(x,0.25))+as.double(quantile(x,0.75)))/2)}
trimedia<-function(x){return((median(x)+PMC(x))/2)}
centrimedia<-function(x){
indices<-(x>quantile(x,0.25)&x<quantile(x,0.75))
valores<-x[indices]
return(sum(valores)/length(valores))
}
RIQ<-function(x){return(quantile(x,0.75)-quantile(x,0.25))}
MEDA<-function(x){return(median(abs(x-median(x))))}
CVc<-function(x){return((quantile(x,0.75)-quantile(x,0.25))/(quantile(x,0.75)+quantile(x,0.25)))}
H1<-function(x){return((quantile(x,0.25)+quantile(x,0.75)-2*median(x))/(2*median(x)))}
H2<-function(x){return(median(x)-(quantile(x,0.1)+quantile(x,0.9))/(2))}
H3<-function(x){return(H2(x)/median(x))}
#Creamos una función que aplique todas estas medidas
descriptivo<-function(x){
temp<-rbind(PMC(x),trimedia(x),centrimedia(x))
rownames(temp)<-c("PMC","Trimedia","Centrimedia")
centralidad<-list(clasica=list(media=mean(x)),resistente=temp)
temp<-rbind(RIQ(x),MEDA(x),CVc(x))
rownames(temp)<-c("Rango Inter-Cuartílico","MEDA","CVc")
dispersion<-list(clasica=list(desviación_típica=sd(x),Coef_varización=sd(x)/mean(x),rango=range(x)),resistente=temp)
temp<-rbind(H1(x),H2(x),H3(x))
rownames(temp)<-c("Asimetría de Yule","Asimetría de Kelly","Asimetría de Kelly adimensional")
forma<-list(clasica=list(skewness=skewness(x),kurtosis=kurtosis(x)),resistente=temp)
cat(names(x))
return(list(centralidad=centralidad,dispersion=dispersion,forma=forma))
}
descriptivo(datos[,2])
hist(col="darkblue",datos[,2],main="Densidad de población")
descriptivo(datos[,3])
hist(col="darkblue",datos[,3],main="Mortalidad infantil")
descriptivo(datos[,4])
hist(col="darkblue",datos[,4],main="Esperanza de vida")
descriptivo(datos[,5])
hist(col="darkblue",datos[,5],main="Porcentaje de población urbana")
descriptivo(datos[,6])
hist(col="darkblue",datos[,6],main="Tasa de médicos por habitante")
descriptivo(datos[,7])
hist(col="darkblue",datos[,7],main="Población del sector agrícola")
descriptivo(datos[,8])
hist(col="darkblue",datos[,8],main="Población del sector servicios")
descriptivo(datos[,9])
hist(col="darkblue",datos[,9],main="Número de libros publicados")
descriptivo(datos[,10])
hist(col="darkblue",datos[,10],main="Cociente entre el número de individuos en ejército de tierra y población total del estado")
descriptivo(datos[,11])
hist(col="darkblue",datos[,11],main="Cociente entre población activa y total")
descriptivo(datos[,12])
hist(col="darkblue",datos[,12],main="Tasa de consumo energético")
summary(datos[,-1])
par(mar=c(1,1,1,1))
par(mfrow=c(3,4))
invisible(apply(datos[,-1], 2,function(x){hist(x,main=NULL,col="darkblue",xlab=NULL,ylab=NULL)}))
colfunc<-colorRampPalette(c("darkblue","yellow"))
boxplot(datos[,-1],
xlab=NULL,
ylab=NULL,
col=colfunc(11),
las=2)
outlier<-function(data,na.rm=T){
H<-1.5*IQR(data)
if(any(data<=(quantile(data,0.25,na.rm = T)-H))){
data[data<=quantile(data,0.25,na.rm = T)-H]<-NA
data[is.na(data)]<-mean(data,na.rm=T)
data<-outlier(data)}
if(any(data>=(quantile(data,0.75, na.rm = T)+H))){
data[data>=quantile(data,0.75, na.rm = T)+H]<-NA
data[is.na(data)]<-mean(data,na.rm=T)
data<-outlier(data)
}
return(data)
}
datos[,-1:-2]<-apply(datos[,-1:-2], 2, outlier)
boxplot(datos[,-1],
xlab=NULL,
ylab=NULL,
col=colfunc(11),
las=2)
par(mar=c(1,1,1,1))
par(mfrow=c(3,4))
invisible(apply(datos[,-1], 2, function(x){
qqnorm(x,main=NULL)
abline(a=0,b=1,col="red")
}))
datos_aux <- datos[,-1]
datos_enteros$continente <- c(
"africa", "africa", "america", "oceania",
"america", "america", "america", "asia",
"asia", "africa", "europa", "asia",
"europa", "europa", "asia", "asia",
"asia", "asia", "europa", "asia", "asia",
"africa", "america", "africa", "asia", "europa",
"europa", "europa", "europa", "europa",
"europa", "asia", "america", "asia")
ind<-which(datos_enteros$continente=="europa"|datos_enteros$continente=="asia"|datos_enteros$continente=="africa")
factores<-datos_enteros$continente[ind]
#Como se han eliminado los valores outlier, usamos con centro la media en vez de la mediana
#H0:homocedasticidad
apply(datos_aux[ind,], 2, function(x){
if(leveneTest(x,as.factor(factores),center=median)$"Pr(>F)"[1]>0.05){
"Existe homocedasticidad entre los grupos"
}
else{"No existe homocedasticidad entre los grupos"}
})
summary(datos_enteros[,c(-1,-13)])
summary(datos[,-1])
datos_pca = datos[,-1] # Eliminamos la primera columna, que es categórica
cor(datos_pca)
poly_cor<-hetcor(datos_pca)$correlations
ggcorrplot(poly_cor, type="lower",hc.order=T)
cor(datos_pca$ZESPVIDA,datos_pca$ZTMINFAN)
cor(datos_pca$ZPAGRICU,datos_pca$ZPOBURB)
cor(datos_pca$ZPSERVI, datos_pca$ZPAGRICU)
cortest.bartlett(cor(datos_pca), n=100)
# scale y center están a True porque consideramos los datos normalizados
PCA<-prcomp(datos_pca, scale=T, center = T)
PCA$rotation
summary(PCA)
varianza_explicada <- PCA$sdev^2 / sum(PCA$sdev^2)
ggplot(data = data.frame(varianza_explicada, pc = 1:11),
aes(x = pc, y = varianza_explicada, fill=varianza_explicada )) +
geom_col(width = 0.3) +
scale_y_continuous(limits = c(0,0.6)) + theme_bw() +
labs(x = "Componente principal", y= " Proporción de varianza explicada")
varianza_acum<-cumsum(varianza_explicada)
ggplot( data = data.frame(varianza_acum, pc = 1:11),
aes(x = pc, y = varianza_acum ,fill=varianza_acum )) +
geom_col(width = 0.5) +
scale_y_continuous(limits = c(0,1)) +
theme_bw() +
labs(x = "Componente principal",
y = "Proporci?n varianza acumulada")
PCA$sdev^2
mean(PCA$sdev^2)
# Entre la PC1 y la PC2
fviz_pca_var(PCA, axes=c(1,2),
repel=TRUE,col.var="cos2",
legend.title="Distancia")+theme_bw()
# Entre la PC1 y la PC3
fviz_pca_var(PCA,axes=c(1,3),
repel=TRUE,col.var="cos2",
legend.title="Distancia")+theme_bw()
#Entre la PC2 y la PC3
fviz_pca_var(PCA,axes=c(2,3),
repel=TRUE,col.var="cos2",
legend.title="Distancia")+theme_bw()
datos_fa = datos_pca
corrplot(cor(datos_fa), order = "hclust", tl.col='black', tl.cex=1,
col=colorRampPalette(c("blue","white","red"))(200))
scree(poly_cor)
fa.parallel(poly_cor,n.obs=200,fa="fa",fm="minres")
factanal(datos_fa,factors=2, rotation="none")
print("###############################################")
factanal(datos_fa,factors=3, rotation="none")
modelo_varimax<-fa(poly_cor,nfactors = 3,rotate = "none",
fa="mle")
print(modelo_varimax$loadings,cut=0)
fa.diagram(modelo_varimax)
datos_da = datos_fa
datos_tidy <- melt(datos_da, value.name = "valor")
aggregate(formula = valor ~ variable, data = datos_tidy,
FUN = function(x){shapiro.test(x)$p.value})
outliers <- mvn(data = datos_da, mvnTest = "hz", multivariateOutlierMethod = "quan")
royston_test <- mvn(data = datos_da, mvnTest = "royston", multivariatePlot = "qq")
royston_test$multivariateNormality
hz_test <- mvn(data = datos_da, mvnTest = "hz")
hz_test$multivariateNormality
datos_ca <- datos_fa
rownames(datos_ca) <- datos$PAIS
distance<- get_dist(datos_ca)
fviz_dist(distance, gradient = list(low ="#00AFBB", mid = "white", high = "#FC4E07"))
set.seed(123)
fviz_nbclust(datos_ca, kmeans, method = "silhouette")
k2 <- kmeans(datos_ca, centers = 2, nstart = 25)
fviz_cluster(k2,data=datos_ca)
print(k2)
factanal(datos_fa,factors=2, rotation="none")
factanal(datos_fa,factors=3, rotation="none")
