################################################################################
# El fichero Datos_mundo.sav contiene, entre otras, las variables znac_def, zmortinf,
# zfertil, zinc_pob, tasa_na, zurbana, zalfabet, zcalor?a, zlog_pib, zpib_cap,
# zpoblac, zdensida, que son las variables estandarizadas de las originales de 
# igual denominaci?n sin la z inicial, y que respectivamente son los valores 
# para cada pa?s del mundo de
# ? Tasa Nacimientos/Defunciones (nac_def)
# ? Mortalidad infantil: muertes por 1000 nacimientos vivos (mortinf)
# ? Fertilidad: n?mero promedio de hijos (fertil)
# ? Aumento de la poblaci?n en % anual (inc_pob)
# ? Tasa de natalidad por 1.000 habitantes (tasa_na)
# ? Habitantes en ciudades en % (urbana)
# ? Personas Alfabetizadas en % (alfabet)
# ? Ingesta diaria de calor?as (calor?as)
# ? Log(10) de PIB_CAP (log_pib)
# ? Producto interior bruto per-capita (pib_cap)
# ? Poblaci?n en miles (poblac)
# ? Habitantes por Km2 (densidad)                                                 
################################################################################

# -------------------------------------- #
# PASO 0: carga de los datos #
# -------------------------------------- #

# La funci?n siguiente informa de cu?l es mi directorio de trabajo
getwd()
# Con la funci?n setwd("Direcci?n en PC") podr?amos cambiar el directorio

library(foreign)
datos<-read.spss("Datos_mundiales.sav", to.data.frame = TRUE)
# La variable "datos" es un data.frame
# Eliminamos las columnas 1 a 31 del data.frame porque nos quedamos con las 
# variables ya enstadarizadas
datos_pca<-datos[,-(1:31)]
# Hay dos variables al final que parecen duplicadas o con informaci?n vaga que tambi?n
# eliminamos
datos_pca<-datos_pca[,-(16:17)]
# Guardo los datos originales porque la variable datos_pca va a cambiar a lo 
# largo del an?lisis
datos_originales<-datos_pca
# La funci?n "head" muestra unos cuantos datos del data.frame aunque trabajmos
# con las 105 muestras de vidrio recogida
head(datos_pca,n=3)

# Se observa que en los datos hay muchos valores perdidos (NA). Hay que hacer 
# un tratamiento detallado de estos valores perdidos. En este caso los vamos a
# sustituir por la media.
not_available<-function(data,na.rm=F){
  data[is.na(data)]<-mean(data,na.rm=T)
  data
}
datos_pca$znac_def<-not_available(datos_pca$znac_def)
datos_pca$zmortinf<-not_available(datos_pca$zmortinf)
datos_pca$zfertil<-not_available(datos_pca$zfertil)
datos_pca$zinc_pob<-not_available(datos_pca$zinc_pob)
datos_pca$ztasa_na<-not_available(datos_pca$ztasa_na)
datos_pca$zurbana<-not_available(datos_pca$zurbana)
datos_pca$zespvida<-not_available(datos_pca$zespvida)
datos_pca$zalfabet<-not_available(datos_pca$zalfabet)
datos_pca$zcalor?a<-not_available(datos_pca$zcalor?a)
datos_pca$zlog_pib<-not_available(datos_pca$zlog_pib)
datos_pca$zpib_cap<-not_available(datos_pca$zpib_cap)
datos_pca$zpoblac<-not_available(datos_pca$zpoblac)
datos_pca$zdensida<-not_available(datos_pca$zdensida)
datos_pca$zlog_pob<-not_available(datos_pca$zlog_pob)
datos_pca$zlogden<-not_available(datos_pca$zlogden)

# PASO 1: ?tiene sentido un ACP?
# --------------------------------------
# Para responder a esta pregunta se comprueba si existe correlaci?n entre las
# variables con la funci?n "cor" del paquete base, que proporciona la matriz
# de correlaciones R
cor(datos_pca)

# El contraste de esfericidad de Bartlett permite comprobar si las correlaciones
# son distintas de 0 de modo significativo. La hip?tesis nula es que det(R)=1
# La funci?n "cortest.bartlett" del paquete "pysch" reliza este test.
# Esta funci?n trabaja con datos normalizados
# Instalaci?n del paquete desde un repositorio en caso de no estar instalado
install.packages("psych")
# Carga del paquete "psych" si est? instalado
library(psych)
# Se normalizan los datos
datos_normalizados<-scale(datos_pca)
# Se hace el test de esfericidad
cortest.bartlett(cor(datos_normalizados))
# Para estos datos se obtiene un test significativo de modo que se rechaza la 
# hip?tesis nula y por tanto los datos no est?n incorrelados

# ------------------------------------------ #
# Paso 2: an?lisis exploratorio de los datos #
# ------------------------------------------ #
# El objetivo es el de localizar outliers que puedan dar lugar a resultados
# err?neos ya que el ACP es muy sensible a valores extremos. Un diagrama de 
# cajas puede dar esta primera informaci?n.
boxplot(datos_pca,main="An?lisis exploratorio de datos",
        xlab="Variables sociodemogr?ficas",
        ylab="z-values",
        col=c(1:15))
# Al obtener el gr?fico con estos datos se observa que muchas variables
# presentan outliers

# Los outliers deben ser tratados de forma independiente por el investigador, 
# de modo que para el ACP es necesario eliminarlos
# La funci?n outlier definida como sigue elimina los outliers sustituy?ndolos
# por los promedios del resto de valores.
# Ejemplo de construcci?n de una funci?n en R
outlier<-function(data,na.rm=T){
  H<-1.5*IQR(data)
  data[data<quantile(data,0.25,na.rm = T)-H]<-NA
  data[data>quantile(data,0.75, na.rm = T)+H]<-NA
  data[is.na(data)]<-mean(data,na.rm=T)
  data
}

# A continuaci?n aplicamos esta funci?n a cada una a de las variables
# que presentan outliers viendo el boxplot
datos_pca$znac_def<-outlier(datos_pca$znac_def)
datos_pca$zmortinf<-outlier(datos_pca$zmortinf)
datos_pca$zespvida<-outlier(datos_pca$zespvida)
datos_pca$zpib_cap<-outlier(datos_pca$zpib_cap)
datos_pca$zpoblac<-outlier(datos_pca$zpoblac)
datos_pca$zdensida<-outlier(datos_pca$zdensida)
datos_pca$zlog_pob<-outlier(datos_pca$zlog_pob)
datos_pca$zlogden<-outlier(datos_pca$zlogden)


# Comparamos los datos originales y los arreglados 
# Esta funci?n divide la salida gr?fica en dos columnas
par(mfrow=c(1,2))
# Boxplot de los datos originales
boxplot(datos_originales,main="Datos originales",
        xlab="Variables sociodemogr?ficas",
        ylab="z-values",
        col=c(1:15))
# Boxplot de los datos corregidos.
boxplot(datos_pca,main="Datos sin outliers",
        xlab="Variables sociodemogr?ficas",
        ylab="z-values",
        col=c(1:15))

# Llegado a este punto se dan las condiciones para realizar un ACP:
# los datos est?n correlados y no hay 'casos raros'

# ----------- #
# Paso 3: ACP #
# ----------- #

# La funci?n "prcomp" del paquete base de R realiza este an?lisis
# Pasamos los par?metros "scale" y "center" a TRUE para consideras
# los datos originales normalizados
PCA<-prcomp(datos_pca, scale=T, center = T)
# El el campo "rotation" del objeto "PCA" es una matrix cuyas columnas
# son los coeficientes de las componentes principales, es decir, el
# peso de cada variable en la correspondiente componente principal
PCA$rotation
# En el campo "sdev" del objeto "PCA" y con la funci?n summary aplicada
# al objeto, obtenemos informaci?n relevante: desviaciones t?picas de 
# cada componente principal, proporci?n de varianza explicada y acumlada.
PCA$sdev
summary(PCA)


# Instalaci?n del paquete desde un repositorio en caso de no estar instalado
install.packages("ggplot2")
# Carga del paquete "ggplot2" si est? instalado
library("ggplot2")

# El siguiente gr?fico muestra la proporci?n de varianza explicada
varianza_explicada <- PCA$sdev^2 / sum(PCA$sdev^2)
ggplot(data = data.frame(varianza_explicada, pc = 1:15),
       aes(x = pc, y = varianza_explicada, fill=varianza_explicada )) +
  geom_col(width = 0.3) +
  scale_y_continuous(limits = c(0,0.6)) + theme_bw() +
  labs(x = "Componente principal", y= " Proporci?n de varianza explicada")

# El siguiente gr?fico muestra la proporci?n de varianza explicada
varianza_acum<-cumsum(varianza_explicada)
ggplot( data = data.frame(varianza_acum, pc = 1:15),
        aes(x = pc, y = varianza_acum ,fill=varianza_acum )) +
  geom_col(width = 0.5) +
  scale_y_continuous(limits = c(0,1)) +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Proporci?n varianza acumulada")

# -------------------------------------------------------------- #
# Paso 4: selecci?n del n?mero de componentes principales ?ptimo #
# -------------------------------------------------------------- #
# Existen diferentes m?todos:
# 1.- M?todo del codo (Cuadras, 2007). Ejercicio: buscar informaci?n (voluntario)
# 2.- A criterio del investigador que elige un porcentaje m?nimo de varianza explicada
# por las componentes principales (no es fiable porque puede dar m?s de las necesarias.
# 3.- En este caso se utiliza la regla de Abdi et al. (2010). Se promedia las varianzas
# explicadas por la componentes principales y se selecciona aquellas cuya proporci?n de 
# varianza explicada supera la media.
# En este caso se eligen tan solo cuatro direcciones principales tal y como se puede ver
# que acumulan casi un 80% de varianza explicada
PCA$sdev^2
mean(PCA$sdev^2)

# Cada componente principal se obtiene de forma sencilla como combinaci?n lineal de todas
# las variables con los coeficientes que indican las columnas de la matriz de rotaci?n
# Ejercicio voluntario: escribir la expresi?n anal?tica de cada componente princial

# -------------------------------------------------------------- #
# Paso 5: Representaci?n gr?fica de las componentes principales  #
# -------------------------------------------------------------- #
# El paquete "factoextra" permite la representaci?n de las componentes principales
# junto con las variables y observaciones del an?lisis de componentes principales.

# Instalaci?n del paquete desde un repositorio en caso de no estar instalado
# El siguiente paquete requiere tener al menos la vesri?n de R 4.0.x
install.packages("factoextra")
# Carga del paquete "factorextra" si est? instalado
library("factoextra")
# Esto produce una comparativa entre la primera y segunda componente principal analizando 
# que variables tienen m?s peso para la definici?n de cada componente principal
fviz_pca_var(PCA,
             repel=TRUE,col.var="cos2",
             legend.title="Distancia")+theme_bw()

# Esto produce una comparativa entre la primera y tercera componente principal analizando 
# que variables tienen m?s peso para la definici?n de cada componente principal
fviz_pca_var(PCA,axes=c(1,3),
             repel=TRUE,col.var="cos2",
             legend.title="Distancia")+theme_bw()

# Esto produce una comparativa entre la segunda y tercera componente principal analizando 
# que variables tienen m?s peso para la definici?n de cada componente principal
fviz_pca_var(PCA,axes=c(2,3),
             repel=TRUE,col.var="cos2",
             legend.title="Distancia")+theme_bw()






# Es posible tambi?n representar las observaciones de los objetos junto con las componentes 
# principales mediante la orden "contrib" de la funci?n "fviz_pca_ind", as? como identificar
# con colores aquellas observaciones que mayor varianza explican de las componentes principales
 
# Observaciones en la primera y segunda componente principal
fviz_pca_ind(PCA,col.ind = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel=TRUE,legend.title="Contrib.var")+theme_bw()

# Observaciones en la primera y tercera componente principal
fviz_pca_ind(PCA,axes=c(1,3),col.ind = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel=TRUE,legend.title="Contrib.var")+theme_bw()

# Observaciones en la segunda y tercera componente principal
fviz_pca_ind(PCA,axes=c(2,3),col.ind = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel=TRUE,legend.title="Contrib.var")+theme_bw()


# Representaci?n conjunta de variables y observaciones
# que relaciona visualmente las posibles relaciones entre las
# observaciones, las contribuciones de los individuos a las varianzas de las componentes
# y el peso de las variables en cada componentes principal

# Variables y observaciones en las 1?  y 2? componente principal
fviz_pca(PCA,
         alpha.ind ="contrib", col.var = "cos2",col.ind="seagreen",
         gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
         repel=TRUE,
         legend.title="Distancia")+theme_bw()

# Variables y observaciones en las 1?  y 3? componente principal
fviz_pca(PCA,axes=c(1,3),
         alpha.ind ="contrib", col.var = "cos2",col.ind="seagreen",
         gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
         repel=TRUE,
         legend.title="Distancia")+theme_bw()

# Variables y observaciones en las 1?  y 2? componente principal
fviz_pca(PCA,axes=c(1,2),
         alpha.ind ="contrib", col.var = "cos2",col.ind="seagreen",
         gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
         repel=TRUE,
         legend.title="Distancia")+theme_bw()



# Por ?ltimo, ya que el objeto de este estudio era reducir la dimensi?n de las variables
# utilizadas, es posible obtener las coordenadas de los datos originales tipificados en el
# nuevo sistema de referencia.
# De hecho lo tenemos almacenado desde que utilizamos la funci?n prcomp para crear la variable PCA

head(PCA$x,n=4)
